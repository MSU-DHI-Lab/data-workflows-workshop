{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 01: Profile the Dataset\n\n",
        "Goal: build professional curiosity about the dataset before writing checks. You'll look at shape, missingness, and unique values.\n"
      ]
    },
	    {
	      "cell_type": "markdown",
	      "metadata": {},
	      "source": [
	        "## 1) Load the CSV\n",
	        "- Do: Provide `collection_cleaned.csv` and run this cell.\n",
	        "- Why: Profiling starts with a clean load so you trust the frame you're inspecting.\n",
	        "- You should see: A dataframe preview with 4 rows and 6 columns.\n",
	        "- If it doesn't look right: Confirm the file is CSV with headers; check the path variable; re-upload if using Colab.\n"
	      ]
	    },
	    {
	      "cell_type": "code",
	      "execution_count": null,
	      "metadata": {},
	      "outputs": [],
	      "source": [
	        "from pathlib import Path\n\nimport pandas as pd\n\n# Update this if your file is somewhere else.\n# In Colab, the most common is: 'collection_cleaned.csv' (uploaded to the Files panel).\npath = '../inputs/collection_cleaned.csv'\n\ncandidates = [\n    Path(path),\n    Path('inputs/collection_cleaned.csv'),\n    Path('collection_cleaned.csv'),\n    Path('/content/collection_cleaned.csv'),\n]\n\ncsv_path = next((p for p in candidates if p.exists()), None)\nif csv_path is None:\n    raise FileNotFoundError(\n        \"Couldn't find 'collection_cleaned.csv'.\\n\\n\"\n        \"Provide the file, then either:\\n\"\n        \"- Put it at '../inputs/collection_cleaned.csv' (relative to this notebook folder), or\\n\"\n        \"- Upload it in Colab so it appears as '/content/collection_cleaned.csv' (aka 'collection_cleaned.csv'), or\\n\"\n        \"- Edit the `path` variable in this cell to match where you put it.\\n\\n\"\n        \"Tried: \" + \", \".join(str(p) for p in candidates)\n    )\n\ndf = pd.read_csv(csv_path)\n\nrequired_columns = {'id', 'title', 'creator', 'place', 'rights', 'date'}\nmissing = required_columns - set(df.columns)\nif missing:\n    raise ValueError(\n        \"CSV loaded, but it's missing expected columns: \"\n        + \", \".join(sorted(missing))\n        + \"\\nFound columns: \"\n        + \", \".join(df.columns)\n    )\n\ndf.head()\n"
	      ]
	    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Check shape and dtypes\n",
        "- Do: Run to see row/column counts and data types.\n",
        "- Why: Confirms the expected structure before writing validation.\n",
        "- You should see: (4, 6) and types showing strings for text fields, int for date if parsed.\n",
        "- If it doesn't look right: Check for extra header rows; ensure date column is numeric or castable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.shape, df.dtypes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Missingness scan\n",
        "- Do: Run to count missing values per column.\n",
        "- Why: Guides which checks to add (e.g., id cannot be missing).\n",
        "- You should see: Zeros across key fields in this sample.\n",
        "- If it doesn't look right: Inspect columns with missing values; confirm they are expected.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Unique values for rights and place\n",
        "- Do: Run to see allowed tokens and place variants.\n",
        "- Why: Informs allowed lists and normalization expectations for validation.\n",
        "- You should see: Rights tokens ['CC BY 4.0', 'Public Domain', 'Rights Reserved']; places ['Albany', 'New York City'].\n",
        "- If it doesn't look right: Check for trailing spaces; adjust allowed lists later in validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['rights'].unique(), df['place'].unique()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
