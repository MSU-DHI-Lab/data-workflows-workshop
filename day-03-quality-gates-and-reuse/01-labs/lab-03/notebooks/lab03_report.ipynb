{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 03: Generate Quality Report with Known Failures\n\n",
        "Goal: run validation on an intentionally flawed dataset, read the failures, and produce a markdown report to share.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Install Pandera (if not already)\n",
        "- Do: Run the install.\n",
        "- Why: Ensure the library is available for this session.\n",
        "- You should see: Install success.\n",
        "- If it doesn't look right: Rerun; confirm runtime has internet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip -q install pandera[pandas]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load schema and bad data\n",
        "- Do: Add the artifacts path, import the schema, and load `../inputs/collection_with_failures.csv`.\n",
        "- Why: Use the same rules on a dataset with known issues to see how failures surface.\n",
        "- You should see: Dataframe preview with some suspect values.\n",
        "- If it doesn't look right: Check paths; ensure the artifacts folder is accessible.\n"
      ]
    },
    {
	      "cell_type": "code",
	      "execution_count": null,
	      "metadata": {},
	      "outputs": [],
	      "source": [
	        "import sys\nfrom pathlib import Path\nimport subprocess\n\n\ndef _find_repo_root(start: Path) -> Path:\n    for candidate in [start] + list(start.parents):\n        if (candidate / 'WORKSHOP_OVERVIEW.md').exists():\n            return candidate\n    return start\n\n\ndef _ensure_repo_root() -> Path:\n    # Colab opens notebooks in /content without repo files. Clone so relative data imports work.\n    if 'google.colab' in sys.modules:\n        repo_root = Path('/content/data-workflows-workshop')\n        if not repo_root.exists():\n            subprocess.run(\n                [\n                    'git',\n                    'clone',\n                    '--depth',\n                    '1',\n                    'https://github.com/MSU-DHI-Lab/data-workflows-workshop.git',\n                    str(repo_root),\n                ],\n                check=True,\n            )\n        return repo_root\n\n    return _find_repo_root(Path.cwd().resolve())\n\n\nREPO_ROOT = _ensure_repo_root()\nLAB03_ROOT = REPO_ROOT / 'day-03-quality-gates-and-reuse/01-labs/lab-03'\nLAB02_DELIVERABLES = REPO_ROOT / 'day-03-quality-gates-and-reuse/01-labs/lab-02/deliverables'\n\nsys.path.append(str(LAB02_DELIVERABLES))\n\nimport pandas as pd\nimport importlib\n\nschema_module = importlib.import_module('validation_schema')\nschema = schema_module.schema\n\ndf_bad = pd.read_csv(LAB03_ROOT / 'inputs/collection_with_failures.csv')\ndf_bad.head()\n"
	      ]
	    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Run validation and capture errors\n",
        "- Do: Validate the bad dataframe in a try/except and collect the errors.\n",
        "- Why: We expect failures; capturing them lets us report clearly.\n",
        "- You should see: A `SchemaErrors` message with details on offending rows.\n",
        "- If it doesn't look right: Ensure the schema import succeeded; check that the CSV has the expected columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandera as pa\nfrom pandera.errors import SchemaErrors\n\ntry:\n    schema.validate(df_bad, lazy=True)\n    validation_errors = None\nexcept SchemaErrors as err:\n    validation_errors = err.failure_cases\n    display(err.failure_cases)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Generate a markdown report\n",
        "- Do: Build a short report with counts and examples of failures.\n",
        "- Why: Reports are artifacts for stakeholders, not only programmers; they tell the story of what failed and why.\n",
        "- You should see: A markdown string with sections you can save.\n",
        "- If it doesn't look right: Check that `validation_errors` is populated; ensure lazy=True was set to collect all failures.\n"
      ]
    },
    {
	      "cell_type": "code",
	      "execution_count": null,
	      "metadata": {},
	      "outputs": [],
	      "source": [
	        "total_rows = len(df_bad)\n",
	        "fail_count = len(validation_errors) if validation_errors is not None else 0\n",
	        "report_lines = [\n",
	        "    '# Quality Report',\n",
	        "    f'- Total rows: {total_rows}',\n",
	        "    f'- Failed checks: {fail_count}',\n",
	        "]\n",
	        "if validation_errors is not None:\n",
	        "    sample = validation_errors.head(10)\n",
	        "    report_lines.append('## Sample failures (first 10)')\n",
	        "    for _, row in sample.iterrows():\n",
	        "        report_lines.append('- Column: {col} | Check: {chk} | Failure: {fail} | Index: {idx}'.format(col=row['column'], chk=row['check'], fail=row['failure_case'], idx=row['index']))\n",
	        "report = '\\n'.join(report_lines)\n",
	        "print(report)\n",
	        "report_path = LAB03_ROOT / 'validation_report.md'\n",
	        "with open(report_path,'w') as f:\n",
	        "    f.write(report)\n",
	        "print(f'Saved report to {report_path}')\n"
	      ]
	    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Reflect\n",
        "- Do: Note which checks caught issues and why they matter.\n",
        "- Why: Helps you decide whether to fix data, adjust checks, or quarantine records.\n",
        "- You should see: Your own notes summarizing next actions.\n",
        "- If it doesn't look right: Review the failure cases table; tie each check to the problem it prevented.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
